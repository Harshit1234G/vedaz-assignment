"""
1. Research Task (Non-Coding | 1-2 Pages PDF)

You are asked to build an LLM-based smart recommendation engine for Vedaz that analyzes user chat history and profile to recommend astrologers.

1. What LLM stack (OpenAI / Hugging Face / open-source like LLaMA) would you recommend and why?

2.How would you host and scale it (cloud provider, deployment options)?

3. Estimate the monthly cost for hosting a production-level LLM inference system for 50,000 monthly active users.

4.What privacy/safety concerns would you address?

What it tests:
Research skills, architecture thinking, cost-awareness, ability to communicate ideas clearly.

2. Technical Task (Coding | 4-5 hours)

Build a mini recommendation engine that takes user inputs (e.g. chat transcript or a mock profile) and returns top 3 astrologers using semantic matching (embeddings, keyword ranking, or fine-tuned model).

Expected output:

A simple Python script or Jupyter Notebook

Astrologer data can be mocked (5-10 entries with tags like love, career, marriage, etc.)

Bonus if they use OpenAI embeddings or Sentence Transformers

Should return relevance score and recommended astrologers

What it tests:
Hands-on NLP experience, prompt engineering, semantic search, quick prototyping, and ability to work with real-world user data structure.

3. Bonus : Small LLM Use Case
Prompt:

Write a prompt or small agent logic that behaves like a basic AI astrologer â€” it should be able to take a palm reading description or horoscope summary and reply with a life insight or advice.
(Use OpenAI, Claude, or open-source LLM, or write pseudocode.)
"""



